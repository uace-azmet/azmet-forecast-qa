---
title: "AZMET QA/QC Report"
date: now
date-format: full
format: 
  html:
    code-fold: true
    toc: true
editor: visual
server: shiny
---

```{r}
#| include: false
#| context: setup

library(tidyverse)
library(azmetr)
library(tictoc) #for timing
library(shiny)
library(gt)
library(pointblank)
library(lubridate)
library(pins)
```

```{r}
#| context: data
#| include: false
#| cache: true
#| cache.extra: !expr Sys.Date()

# Get full updated data from the API. This *should* be cached at the app level,
# so there will be a long loading time only for the first person to launch the
# app every day.

tic()
daily <- azmetr::az_daily(start_date = "2020-01-01")
toc() # about 25 seconds

tic()
hourly <- azmetr::az_hourly(start_date_time = "2020-01-01 00")
toc() # about 333 seconds

board <- board_connect()
fc_daily <- board |> pin_read("ericrscott/fc_daily")
```

This report uses the `pointblank` package for displaying data validation results.
In the tables below the "STEP" column contains the name of the validation function, but you can mouse over it for a more human-readable description.
The UNITS column is how many rows were tested, PASS and FAIL columns show the number (upper) and fraction (lower) of rows that pass or fail the validation step.
The W S N column shows whether this step triggered a warning, a stop, or a notification.
The EXT column contains a blue CSV button to download ("EXTract") the failed rows for the validation for you to inspect.
Find more on the anatomy of this table in the `pointblank` [documentation](https://rich-iannone.github.io/pointblank/articles/VALID-I.html#a-simple-example-with-the-basics).

# Consistency checks

```{r}
#slider input might be better?
dateRangeInput(
  "daterange",
  "Date Range",
  min = ymd("2020-12-30"),
  max = today(),
  start = today() - 14,
  end = today()
)
```

## Daily Data

```{r}
#| column: body-outset
gt_output(outputId = "check_daily")
```

```{r}
#| context: server

al <- action_levels(warn_at = 1, stop_at = 0.1)

output$check_daily <-
  gt::render_gt({
    
    start <- input$daterange[1]
    end <- input$daterange[2]
    
    daily_check <-
      daily |>
      filter(datetime > start & datetime <= end) |>
      create_agent(
        # tbl_name = "Daily Data Consistency Checks",
        # label = "Consistency Checks",
        actions = al
      ) |>
      # Internal consistency checks from 'NWS (1994) TSP 88-21-R2':
      col_vals_gte(temp_air_meanC, vars(dwpt_mean), na_pass = TRUE) |>
      col_vals_lte(temp_air_minC, vars(temp_air_meanC), na_pass = TRUE) |>
      col_vals_lte(temp_air_meanC, vars(temp_air_maxC), na_pass = TRUE) |>
      col_vals_lte(wind_spd_mean_mps, vars(wind_spd_max_mps), na_pass = TRUE) |>
      col_vals_lte(temp_soil_10cm_meanC, vars(temp_soil_10cm_maxC), na_pass = TRUE) |>
      col_vals_lte(temp_soil_10cm_minC, vars(temp_soil_10cm_meanC), na_pass = TRUE) |>
      col_vals_lte(temp_soil_50cm_meanC, vars(temp_soil_50cm_maxC), na_pass = TRUE) |>
      col_vals_lte(temp_soil_50cm_minC, vars(temp_soil_50cm_meanC), na_pass = TRUE) |>
      col_vals_lte(relative_humidity_mean,
                   vars(relative_humidity_max),
                   na_pass = TRUE) |>
      col_vals_lte(relative_humidity_min,
                   vars(relative_humidity_mean),
                   na_pass = TRUE) |>

      #TODO calculate max sol radiation based on date and location and check for that
      # col_vals_lt(sol_rad_total, sol_rad_expected, preconditions = ~calc_sol(date))
      interrogate()
    get_agent_report(daily_check, title = "Daily Consistency Checks")
  })
```

## Hourly Data

```{r}
#| column: body-outset

gt_output(outputId = "check_hourly")
```

```{r}
#| context: server

output$check_hourly <- 
  gt::render_gt({
    
    start <- input$daterange[1]
    end <- input$daterange[2]
    
    hourly_check <- hourly |> 
      filter(date_datetime > start & date_datetime <= end) |>
      create_agent(
        tbl_name = "Hourly measures",
        label = "Consistency Checks",
        actions = al
      ) |> 
      
      # Internal consistency checks from 'NWS (1994) TSP 88-21-R2':
      col_vals_gte(
        temp_airC,
        vars(dwpt),
        na_pass = TRUE,
        #account for rounding error I guess?
        preconditions = function(x) x |> mutate(dwpt = dwpt - 0.2)
      ) |> 
      col_vals_lte(wind_spd_mps, vars(wind_spd_max_mps), na_pass = TRUE) |> 
      
      # Temporal consistency checks from 'NWS (1994) TSP 88-21-R2':
      col_vals_lt(
        temp_airC_delta,
        19.4, 
        na_pass = TRUE,
        brief = "Expect that |∆`temp_airC`| < 19.4",
        preconditions = function(x) x |> 
          group_by(meta_station_id) |> 
          mutate(temp_airC_delta = abs(temp_airC - lag(temp_airC)),
                 .after = temp_airC) |> 
          ungroup()
      ) |> 
      col_vals_lt(
        relative_humidity_delta,
        50,
        na_pass = TRUE,
        brief = "Expect that |∆`relative_humidity`| < 50",
        preconditions = function(x) x |> 
          group_by(meta_station_id) |> 
          mutate(relative_humidity_delta = abs(relative_humidity - lag(relative_humidity)),
                 .after = relative_humidity) |> 
          ungroup()
      ) |> 
      col_vals_lt(
        wind_spd_mps_delta,
        10.3,
        na_pass = TRUE,
        brief = "Expect that |∆`wind_spd_mps`| < 10.3",
        preconditions = function(x) x |> 
          group_by(meta_station_id) |> 
          mutate(wind_spd_mps_delta = abs(wind_spd_mps - lag(wind_spd_mps)),
                 .after = wind_spd_mps) |> 
          ungroup()
      ) |> 
      
      # Temporal consistency ('persistence') checks:
      col_vals_equal(
        sol_rad_total_14,
        FALSE, #true means < 1 for the past 14 hours
        na_pass = TRUE,
        brief = "Expect that sol_rad_total should not be < 1 for more than 14 hours",
        preconditions = function(x) x |> 
          group_by(meta_station_id) |> 
          mutate(
            sol_rad_total_14 = slider::slide_lgl(
              sol_rad_total, ~all(.x < 0.01),
              .after = 14, #.after because arrange(desc(datetime))
              .complete = TRUE
            )
          ) |> ungroup()
      ) |> 
      col_vals_equal(
        wind_spd_mps_14,
        FALSE, #true means < 1 for the past 14 hours
        na_pass = TRUE,
        brief = "Expect that wind_spd_mps should not be < 1 for more than 14 hours",
        preconditions = function(x) x |> 
          group_by(meta_station_id) |> 
          mutate(
            #slide_lgl turns an anonymous function into a sliding window function
            wind_spd_mps_14 = slider::slide_lgl(
              wind_spd_mps, ~all(.x < 0.01),
              .after = 14, #.after because arrange(desc(datetime))
              .complete = TRUE
            )
          ) |> ungroup()
      ) |> 
      col_vals_equal(
        wind_vector_dir_14,
        FALSE, #true means < 1 for the past 14 hours
        na_pass = TRUE,
        brief = "Expect that wind_vector_dir should not be < 1 for more than 14 hours",
        preconditions = function(x) x |> 
          group_by(meta_station_id) |> 
          mutate(
            wind_vector_dir_14 = slider::slide_lgl(
              wind_vector_dir, ~all(.x < 1),
              .after = 14, #.after because arrange(desc(datetime))
              .complete = TRUE
            )
          ) |> ungroup()
      ) |> 
      interrogate()
    
    get_agent_report(hourly_check, title = "Hourly Data Consistency Check")
  })
```

# Forecast-based validation

For these validations, a timeseries model is fit to past data, a forecast for the current day is made, and that forecast is compared to observed values.
If observed values are outside the 99% predictive interval of the forecast then the value doesn't pass the validation.
Interpret these validations with caution---a failing validation does not necessarily mean there is a problem with the data and could just represent an extreme event.
Check the plots below as well.

::: {.callout-note collapse="true"}
## Expand to see model details

Timeseries models are fit using a non-seasonal ARIMA model using a fourier terms to capture seasonality.
The maximum order of the fourier terms (`K`) is estimated for each weather variable to minimize model AIC.
An auto-ARIMA function is used for the non-seasonal ARIMA part of the model and the order of the coefficients $p$, $d$, and $q$ are estimated separately for each weather variable and each *station*.

This is done using the `fable` package with something like the following (pseudo-code):

``` r
for (i in 1:25) {
  fit <- df |> model(
    ARIMA( ~ pdq() + PDQ(0,0,0) + xreg(fourier(period = '1 year', K = i)))
  )
  fit_aicc <- fit$AICc
  if(fit_aicc < bestfit) {
    bestfit <- fit_aicc
  } else {
    return(fit)
  }
}
```

The maximum order of the Fourier series, the order of the ARIMA coefficients, and the estimates for the coefficients are only estimated once per year.
Each day, the model is re-fit to new data (but not re-estimated) before being used to forecast.
:::

To read the `pointblank` table, hover over the TBL column to see which variable each row corresponds to

::: callout-important
A few variables are excluded from this validation because these timeseries models are inappropriate for them: `wind_vector_dir` is in polar coordinates, `sol_rad_total` and `precip_total_mm` because they are highly zero-inflated.
:::

```{r}
#| column: body-outset

gt_output(outputId = "check_forecast")
```


```{r}
#| context: server

output$check_forecast <- 
  gt::render_gt({
    
    start <- input$daterange[1]
    end <- input$daterange[2]
    
    forecast_validation <- 
      fc_daily |>  
      filter(datetime > start & datetime <= end) |> 
      create_agent(
        tbl_name = "Daily Measures",
        label = "Forecast-Based Validations",
        actions = al
      ) |> 
      col_vals_between(
        obs, vars(lower_99), vars(upper_99), segments = vars(varname)
      ) |> 
      interrogate()
    get_agent_report(forecast_validation, title = "Forecast-based Validation (Daily Data)")
  })
```
